{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_unused_features = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load both datasets\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# put in one dataframe\n",
    "df = pd.concat([train, test])\n",
    "df.reset_index(drop=True)\n",
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show sample row\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing Values\n",
    "if not ignore_unused_features:\n",
    "    # cloud coverage: 0 if no events, 8 if events\n",
    "    for row in range(len(df)):\n",
    "        if row % 10000 == 0:\n",
    "            clear_output()\n",
    "            print(\"Working on row {}\".format(row))\n",
    "        if np.isnan(df.loc[row, 'CloudCover']):\n",
    "            if df.loc[row, 'Events'] is np.nan:\n",
    "                df.loc[row, 'CloudCover'] = 0\n",
    "            else:\n",
    "                df.loc[row, 'CloudCover'] = 8\n",
    "\n",
    "    # max gust speed = max wind speed\n",
    "    df.Max_Gust_SpeedKm_h = df.Max_Gust_SpeedKm_h.fillna(df.Max_Wind_SpeedKm_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ignore_unused_features:\n",
    "    # No-Events (NaN) are considered as sunny days, with lowest value (0) on the events scale\n",
    "    df['Events'] = df['Events'].fillna(0)\n",
    "    df=df.replace({'Rain':1, 'Thunderstorm':1, 'Fog':1, 'Snow': 2, 'Fog-Rain': 2, 'Rain-Thunderstorm': 2, 'Rain-Snow':2, 'Fog-Snow':2, 'Fog-Rain-Snow':3, 'Rain-Hail':3, 'Snow-Hail':3, 'Rain-Snow-Hail':3, 'Fog-Rain-Hail':3, 'Fog-Thunderstorm':3, 'Fog-Rain-Thunderstorm':4, 'Fog-Snow-Hail':4, 'Fog-Rain-Snow-Hail':4, 'Rain-Snow-Thunderstorm':4, 'Rain-Hail-Thunderstorm':4, 'Fog-Rain-Hail-Thunderstorm':4, 'Rain-Snow-Hail-Thunderstorm':4})\n",
    "    df['Events'].unique()\n",
    "    # Sistemo i dati per regression tree\n",
    "\n",
    "    # One-Hot Encoding \n",
    "    df = pd.get_dummies(df, columns=['StoreType'], prefix='StoreType')\n",
    "    df = pd.get_dummies(df, columns=['AssortmentType'], prefix='AssortmentType')\n",
    "    df = pd.get_dummies(df, columns=['Region'], prefix='Region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add date features\n",
    "Add new features:\n",
    "- day of the week \n",
    "- month \n",
    "- week of the year \n",
    "- quarter of the year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Date Features\n",
    "# convert date to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# add features\n",
    "df['DayOfWeek']=df['Date'].dt.dayofweek\n",
    "df['Month']=df['Date'].dt.month\n",
    "df['Week']=df['Date'].dt.weekofyear\n",
    "df['Quarter']=df['Date'].dt.quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add one-day-distance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Temporal Features\n",
    "# create columns\n",
    "df['IsOpen_yesterday'] = np.empty(len(df))\n",
    "df['IsOpen_tomorrow'] = np.empty(len(df))\n",
    "df['IsHoliday_yesterday'] = np.empty(len(df))\n",
    "df['IsHoliday_tomorrow'] = np.empty(len(df))\n",
    "df['HasPromotions_yesterday'] = np.empty(len(df))\n",
    "df['HasPromotions_tomorrow'] = np.empty(len(df))\n",
    "\n",
    "for store in df.StoreID.unique():\n",
    "    clear_output()\n",
    "    print(\"Working on {}\".format(store))\n",
    "    temp = df.loc[df.StoreID == store]\n",
    "    # switch index to timestamps to make this easier\n",
    "    oldindex = temp.index\n",
    "    temp.index = temp['Date']\n",
    "    \n",
    "    temp['IsOpen_yesterday'] = temp.IsOpen.rolling(window='1d',closed='left', min_periods=1).sum()\n",
    "    temp['IsOpen_tomorrow'] = temp.IsOpen.rolling(window='1d',closed='left', min_periods=1).sum().shift(-2, '1d')\n",
    "    temp['IsHoliday_yesterday'] = temp.IsHoliday.rolling(window='1d',closed='left', min_periods=1).sum()\n",
    "    temp['IsHoliday_tomorrow'] = temp.IsHoliday.rolling(window='1d',closed='left', min_periods=1).sum().shift(-2, '1d')  \n",
    "    temp['HasPromotions_yesterday'] = temp.HasPromotions.rolling(window='1d',closed='left', min_periods=1).sum()\n",
    "    temp['HasPromotions_tomorrow'] = temp.HasPromotions.rolling(window='1d',closed='left', min_periods=1).sum().shift(-2, '1d')  \n",
    "   \n",
    "    # put it back in the dataframe\n",
    "    temp.index = oldindex\n",
    "    df.loc[df.StoreID == store] = temp\n",
    "\n",
    "# fix edge days\n",
    "df.IsOpen_yesterday.fillna(1, inplace = True)\n",
    "df.IsOpen_tomorrow.fillna(1, inplace = True)\n",
    "df.IsHoliday_yesterday.fillna(0, inplace = True)\n",
    "df.IsHoliday_tomorrow.fillna(0, inplace = True)\n",
    "df.HasPromotions_yesterday.fillna(0, inplace=True)\n",
    "df.HasPromotions_tomorrow.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns\n",
    "- NumberOfCustumers : not present in  the testset\n",
    "- WindDirDegrees : useless\n",
    "- Visibility: too many missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns\n",
    "df['NumberOfCustomers'] = np.nan\n",
    "df = df.drop('NumberOfCustomers', axis=1)  \n",
    "df = df.drop('WindDirDegrees', axis=1)\n",
    "df = df.drop('Max_VisibilityKm', axis=1)\n",
    "df = df.drop('Mean_VisibilityKm', axis=1)\n",
    "df = df.drop('Min_VisibilitykM', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns with redundant information\n",
    "Region_AreaKM2, Region_GDP and Region_PupolationK have the same info (different number for each region). Keep only one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we keep the region population\n",
    "df = df.drop('Region_AreaKM2', axis=1)\n",
    "df = df.drop('Region_GDP', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop days when the stores are closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with IsOpen = 0\n",
    "# -> the number of sales is always = 0 \n",
    "df = df[df.IsOpen == 1]\n",
    "# drop the now useless column\n",
    "df = df.drop('IsOpen', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add features: store average sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "df_train = df[df.Date < datetime(2018, 3, 1, 0, 0, 0)]\n",
    "df_test = df[df.Date >= datetime(2018, 3, 1, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add temporary feature\n",
    "df_train['Year'] = df_train['Date'].dt.year\n",
    "\n",
    "for store in df.StoreID.unique():\n",
    "    clear_output()\n",
    "    print('store ', store)\n",
    "    mask = (df_train.StoreID == store)\n",
    "    mask_test = (df_test.StoreID == store)\n",
    "    store_df = df_train[mask]\n",
    "\n",
    "    # avg daily sales\n",
    "    available_months = store_df.Month.unique()\n",
    "    available_years = store_df.Year.unique()\n",
    "    total_sales = sum(store_df.NumberOfSales)\n",
    "    total_open_days = store_df.Date.count()\n",
    "    daily_sales = total_sales / total_open_days\n",
    "    df_train.loc[mask, 'daily_sales'] = daily_sales\n",
    "    df_test.loc[mask_test, 'daily_sales'] = daily_sales\n",
    "\n",
    "    # avg sales for each month (BASED ON specific MONTH, not just average of all months)\n",
    "    for m in available_months:\n",
    "        month_avg_sales = sum(store_df[(store_df.Month == m)].NumberOfSales)/len(store_df[(store_df.Month == m)].Year.unique())\n",
    "        df_train.loc[((mask) & (df_train.Month == m)), 'month_avg_sales'] = month_avg_sales\n",
    "        if m in (3, 4):\n",
    "            df_test.loc[((mask_test) & (df_test.Month == m)), 'month_avg_sales'] = month_avg_sales\n",
    "    \n",
    "    # avg yearly sales\n",
    "    yearly_sales = sum(store_df.NumberOfSales)/len(store_df['Year'].unique())\n",
    "    df_train.loc[mask , 'yearly_sales'] = yearly_sales\n",
    "    df_test.loc[mask_test, 'yearly_sales'] = yearly_sales\n",
    "    \n",
    "df_train = df_train.drop('Year', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add features: linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put back in one dataframe\n",
    "df = pd.concat([df_train, df_test])\n",
    "df.reset_index(drop=True)\n",
    "del df_train\n",
    "del df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare date as number for the regression\n",
    "print('Converting date to a number...')\n",
    "df['DateNumeric'] = df['Date'].values.astype(float)\n",
    "    \n",
    "# add temporary columns to compute splits\n",
    "df['Year_temp'] = df['Date'].dt.year\n",
    "df['Month_temp'] = df['Date'].dt.month\n",
    "\n",
    "# get all year-month pairs\n",
    "l = sorted(list(set(df[['Year_temp', 'Month_temp']].itertuples(index=False))))\n",
    "\n",
    "# drop temporary columns\n",
    "df = df.drop(['Year_temp', 'Month_temp'], axis=1)\n",
    "\n",
    "# cycle on two months at a time\n",
    "print('Number of months: {}'.format(len(l)))\n",
    "l = [(l[i], l[i+1]) for i in range(0, len(l), 2)]\n",
    "print('Number of folds: {}'.format(len(l) - 1))\n",
    "\n",
    "# declare new features\n",
    "print('Declaring new features...')\n",
    "df['regression_whole'] = np.empty(len(df))\n",
    "df['regression_twomonths'] = np.empty(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 2 months = NaN\n",
    "print('First two months...')\n",
    "first_two_months = (df.Date < datetime(2016, 5, 1, 0, 0, 0))\n",
    "df.loc[first_two_months, 'regression_whole'] = np.nan\n",
    "df.loc[first_two_months, 'regression_twomonths'] = np.nan\n",
    "\n",
    "# following months: linear regression\n",
    "\n",
    "# version trained on all preceding months\n",
    "kf = TimeSeriesSplit(len(l) - 1)\n",
    "\n",
    "print('Preparing indexes...')\n",
    "indexes = []\n",
    "for train_months_idx, target_months_idx in kf.split(l):\n",
    "    train_months = [l[i] for i in train_months_idx]\n",
    "    target_months = [l[i] for i in target_months_idx]\n",
    "    # flatten\n",
    "    train_months = [x for y in train_months for x in y]\n",
    "    target_months = [x for y in target_months for x in y]\n",
    "    train_indexes = df.Date.apply(lambda d: (d.year, d.month) in train_months)\n",
    "    target_indexes = df.Date.apply(lambda d: (d.year, d.month) in target_months)\n",
    "    indexes.append((train_indexes, target_indexes))\n",
    "\n",
    "# iterate 2 months at a time\n",
    "fold = 0\n",
    "for train_indexes, target_indexes in indexes:\n",
    "    fold += 1\n",
    "    print('Fold {}'.format(fold))\n",
    "    for store in df.StoreID.unique():\n",
    "        for day in (0, 1, 2, 3, 4, 5, 6):\n",
    "            # fit linear regression on sales and HasPromotions\n",
    "            mask = (train_indexes) & (df.StoreID == store) & (df.DayOfWeek == day)\n",
    "            X = df.loc[mask, ['DateNumeric', 'HasPromotions']]\n",
    "            y = df.loc[mask, 'NumberOfSales']      \n",
    "            target_mask = (target_indexes) & (df.StoreID == store) & (df.DayOfWeek == day)\n",
    "            if len(X) == 0:\n",
    "                # leave empty\n",
    "                df.loc[target_mask, 'regression_whole'] = np.nan\n",
    "            else:\n",
    "                target_X = df.loc[target_mask, ['DateNumeric', 'HasPromotions']]\n",
    "                if len(target_X) == 0:\n",
    "                    # skip\n",
    "                    continue\n",
    "                # predict following two months\n",
    "                model = LinearRegression()\n",
    "                model.fit(X, y)\n",
    "                df.loc[target_mask, 'regression_whole'] = model.predict(target_X)\n",
    "        \n",
    "        \n",
    "# version trained on the two preceding months\n",
    "kf = TimeSeriesSplit(len(l) - 1, max_train_size=1)\n",
    "\n",
    "print('Preparing indexes...')\n",
    "indexes = []\n",
    "for train_months_idx, target_months_idx in kf.split(l):\n",
    "    train_months = [l[i] for i in train_months_idx]\n",
    "    target_months = [l[i] for i in target_months_idx]\n",
    "    # flatten\n",
    "    train_months = [x for y in train_months for x in y]\n",
    "    target_months = [x for y in target_months for x in y]\n",
    "    train_indexes = df.Date.apply(lambda d: (d.year, d.month) in train_months)\n",
    "    target_indexes = df.Date.apply(lambda d: (d.year, d.month) in target_months)\n",
    "    indexes.append((train_indexes, target_indexes))\n",
    "\n",
    "# iterate 2 months at a time\n",
    "fold = 0\n",
    "for train_indexes, target_indexes in indexes:\n",
    "    fold += 1\n",
    "    print('Fold {}'.format(fold))\n",
    "    for store in df.StoreID.unique():\n",
    "        for day in (0, 1, 2, 3, 4, 5, 6):\n",
    "            # fit linear regression on sales and HasPromotions\n",
    "            mask = (train_indexes) & (df.StoreID == store) & (df.DayOfWeek == day)\n",
    "            X = df.loc[mask, ['DateNumeric', 'HasPromotions']]\n",
    "            y = df.loc[mask, 'NumberOfSales']      \n",
    "            target_mask = (target_indexes) & (df.StoreID == store) & (df.DayOfWeek == day)\n",
    "            if len(X) == 0:\n",
    "                # leave empty\n",
    "                df.loc[target_mask, 'regression_twomonths'] = np.nan\n",
    "            else:\n",
    "                target_X = df.loc[target_mask, ['DateNumeric', 'HasPromotions']]\n",
    "                if len(target_X) == 0:\n",
    "                    # skip\n",
    "                    continue\n",
    "                # predict following two months\n",
    "                model = LinearRegression()\n",
    "                model.fit(X, y)\n",
    "                df.loc[target_mask, 'regression_twomonths'] = model.predict(target_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop temporary column\n",
    "df = df.drop('DateNumeric', axis=1)\n",
    "\n",
    "# add another useful feature\n",
    "df['RegressionDistance'] = df.Date.apply(lambda x: x.day + ((x.month + 1) % 2) * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe again\n",
    "df_train = df[df.Date < datetime(2018, 3, 1, 0, 0, 0)]\n",
    "df_test = df[df.Date >= datetime(2018, 3, 1, 0, 0, 0)]\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "df_train.to_csv('preprocessed_train_complete.csv', index=False)\n",
    "df_test.to_csv('preprocessed_test_complete.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose features\n",
    "\n",
    "selected_features = [\n",
    "    'NumberOfSales',\n",
    "    'HasPromotions',\n",
    "    'IsOpen_yesterday',\n",
    "    'IsOpen_tomorrow',\n",
    "    'IsHoliday_tomorrow',\n",
    "    'IsHoliday_yesterday',\n",
    "    'daily_sales',\n",
    "    'month_avg_sales',\n",
    "    'yearly_sales',\n",
    "    'NearestCompetitor',\n",
    "    'DayOfWeek',\n",
    "    'Week',\n",
    "    'Month',\n",
    "    'regression_whole',\n",
    "    'RegressionDistance',\n",
    "    'StoreID' # we need this to group the predictions later\n",
    "    ]\n",
    "\n",
    "df_train = df_train[selected_features]\n",
    "df_test = df_test[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for features with NaN values\n",
    "null_cols = []\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].isnull().values.any():\n",
    "        null_cols.append(col)\n",
    "\n",
    "print('Features with NaN: {}'.format(len(null_cols)))\n",
    "for col in null_cols:\n",
    "    print(col)\n",
    "print('Num of rows containing NaNs: {}'.format(len(pd.isnull(df_train).any(1).nonzero()[0])))\n",
    "    \n",
    "# drop all rows with NaN values\n",
    "# the first two months are inevitable since we can't apply the regression\n",
    "inds = pd.isnull(df).any(1).nonzero()[0]\n",
    "df_train = df_train.drop(df_train.index[inds])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['NumberOfSales', 'StoreID'], axis=1)\n",
    "y_train = df_train[\"NumberOfSales\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(n_estimators=300, max_depth=15, random_state=0, n_jobs=2, max_features='sqrt')\n",
    "model = forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show model most important features\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.title(\"Feature importances\", fontsize=20)\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"brown\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), X.columns[indices],rotation=90)\n",
    "ax = plt.axes()\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(16) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(16)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(['NumberOfSales', 'StoreID'], axis=1)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare predictions dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(columns = ['StoreID', 'Month', 'NumberOfSales'] )\n",
    "final.Month = df_test.Month\n",
    "final.StoreID = df_test.StoreID\n",
    "final.NumberOfSales= y_pred\n",
    "final = final.groupby(['StoreID', 'Month'], as_index=False).agg({\"NumberOfSales\":\"sum\"})\n",
    "final.NumberOfSales = final.NumberOfSales.astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"predictions.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
