{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN-TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from IPython.display import clear_output\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nan_features(df):\n",
    "    null_cols = []\n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().values.any():\n",
    "            null_cols.append(col)\n",
    "    return null_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_rows(df):\n",
    "    # getting indices (rows) of all NaN values\n",
    "    inds = pd.isnull(df).any(1).nonzero()[0]\n",
    "\n",
    "    # drop all the rows with NaN values\n",
    "    return df.drop(df.index[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, train_fraction):\n",
    "    mindate = df.Date.min()\n",
    "    maxdate = df.Date.max()\n",
    "    splitdate = mindate + (maxdate - mindate) * train_fraction\n",
    "    train = df[df.Date < splitdate]\n",
    "    test = df[df.Date >= splitdate]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(df):\n",
    "    # split set in data and target\n",
    "    X = df.drop('NumberOfSales', axis=1)\n",
    "    y = df[\"NumberOfSales\"]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    # fit random forest with 250 trees\n",
    "    forest = RandomForestRegressor(n_estimators=250, random_state=0, n_jobs=3)\n",
    "    forest.fit(X_train, y_train)\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load preprocessed csv to dataframe\n",
    "df = pd.read_csv('preprocessed_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [1001, 1009, 1019, 1037, 1038, 1070, 1094, 1132, 1175, 1177, 1185, 1215, 1230, 1251, 1266, 1308, 1325, 1328, 1334, 1347, 1350, 1354, 1372, 1374, 1382, 1383, 1405, 1406, 1441, 1442, 1447, 1449, 1475, 1490, 1493, 1504, 1508, 1514, 1531, 1550, 1560, 1576, 1582, 1596, 1611, 1649, 1664, 1674, 1684, 1689, 1695, 1697, 1710, 1726], 1: [1015, 1024, 1048, 1055, 1067, 1072, 1107, 1144, 1147, 1295, 1302, 1377, 1419, 1461, 1471, 1489, 1568, 1572, 1591, 1605, 1612, 1633, 1713, 1724], 2: [1004, 1016, 1031, 1039, 1043, 1044, 1045, 1051, 1056, 1057, 1068, 1075, 1079, 1082, 1093, 1096, 1097, 1100, 1103, 1105, 1112, 1117, 1119, 1121, 1123, 1131, 1133, 1136, 1154, 1161, 1163, 1166, 1178, 1179, 1201, 1202, 1220, 1226, 1243, 1254, 1256, 1268, 1282, 1285, 1287, 1288, 1290, 1292, 1301, 1335, 1343, 1344, 1345, 1346, 1356, 1358, 1360, 1366, 1368, 1371, 1379, 1391, 1395, 1407, 1410, 1414, 1415, 1417, 1418, 1422, 1423, 1425, 1426, 1435, 1455, 1456, 1473, 1476, 1478, 1483, 1497, 1501, 1503, 1505, 1506, 1509, 1510, 1511, 1515, 1533, 1541, 1542, 1556, 1565, 1569, 1574, 1579, 1585, 1586, 1588, 1594, 1595, 1597, 1598, 1601, 1603, 1617, 1625, 1632, 1642, 1651, 1653, 1655, 1659, 1665, 1670, 1673, 1675, 1705, 1708, 1715, 1717, 1719], 3: [1002, 1013, 1021, 1026, 1029, 1033, 1050, 1060, 1061, 1078, 1084, 1088, 1089, 1114, 1120, 1142, 1150, 1152, 1160, 1176, 1180, 1181, 1188, 1197, 1198, 1207, 1235, 1238, 1241, 1245, 1252, 1260, 1263, 1267, 1272, 1280, 1286, 1298, 1316, 1319, 1320, 1327, 1339, 1355, 1357, 1361, 1362, 1363, 1376, 1390, 1400, 1402, 1411, 1412, 1416, 1420, 1424, 1428, 1452, 1459, 1463, 1469, 1491, 1494, 1538, 1543, 1548, 1552, 1554, 1563, 1570, 1604, 1606, 1621, 1626, 1636, 1637, 1641, 1657, 1661, 1662, 1676, 1678, 1682, 1683, 1696, 1698, 1702, 1706, 1727], 4: [1012, 1018, 1085, 1129, 1146, 1240, 1275, 1304, 1313, 1322, 1507, 1580, 1589, 1592, 1639, 1692, 1699, 1701], 5: [1020, 1022, 1030, 1041, 1053, 1059, 1063, 1076, 1101, 1104, 1115, 1118, 1127, 1128, 1139, 1153, 1172, 1221, 1225, 1250, 1258, 1269, 1277, 1294, 1309, 1311, 1321, 1324, 1340, 1386, 1397, 1398, 1404, 1429, 1436, 1444, 1458, 1482, 1496, 1498, 1499, 1522, 1539, 1553, 1567, 1578, 1680, 1703, 1721], 6: [1025, 1028, 1064, 1099, 1106, 1109, 1148, 1159, 1165, 1171, 1182, 1189, 1190, 1208, 1211, 1231, 1246, 1284, 1300, 1305, 1333, 1348, 1401, 1440, 1454, 1468, 1523, 1571, 1587, 1634, 1646, 1654, 1667, 1669, 1688], 7: [1000, 1003, 1014, 1052, 1073, 1092, 1134, 1141, 1155, 1164, 1170, 1187, 1203, 1210, 1216, 1227, 1228, 1237, 1239, 1244, 1253, 1257, 1270, 1271, 1278, 1279, 1283, 1289, 1293, 1296, 1312, 1318, 1326, 1331, 1359, 1369, 1384, 1387, 1427, 1434, 1457, 1464, 1465, 1479, 1500, 1526, 1534, 1549, 1555, 1590, 1602, 1624, 1631, 1640, 1643, 1658, 1660, 1685, 1709, 1718, 1734], 8: [1034, 1042, 1046, 1074, 1157, 1192, 1200, 1247, 1249, 1276, 1307, 1341, 1342, 1477, 1485, 1486, 1492, 1513, 1524, 1525, 1527, 1528, 1530, 1546, 1583, 1619, 1650], 9: [1005, 1008, 1010, 1011, 1017, 1032, 1035, 1047, 1049, 1054, 1058, 1062, 1066, 1069, 1077, 1080, 1083, 1087, 1091, 1098, 1110, 1111, 1130, 1137, 1138, 1143, 1149, 1151, 1156, 1158, 1167, 1168, 1169, 1173, 1174, 1183, 1186, 1194, 1195, 1199, 1213, 1214, 1223, 1224, 1229, 1233, 1234, 1236, 1242, 1248, 1259, 1264, 1265, 1273, 1281, 1291, 1297, 1306, 1310, 1315, 1317, 1330, 1332, 1338, 1352, 1353, 1364, 1365, 1367, 1370, 1373, 1375, 1378, 1380, 1381, 1385, 1388, 1389, 1392, 1396, 1399, 1408, 1409, 1413, 1430, 1433, 1438, 1443, 1448, 1450, 1451, 1453, 1460, 1466, 1467, 1470, 1472, 1474, 1481, 1487, 1495, 1512, 1516, 1519, 1520, 1529, 1532, 1535, 1537, 1540, 1544, 1545, 1558, 1559, 1561, 1564, 1566, 1573, 1577, 1581, 1584, 1593, 1599, 1600, 1607, 1608, 1610, 1616, 1618, 1620, 1622, 1623, 1627, 1628, 1629, 1630, 1635, 1638, 1647, 1648, 1652, 1656, 1663, 1668, 1671, 1672, 1677, 1679, 1681, 1686, 1690, 1691, 1693, 1700, 1704, 1712, 1716, 1723, 1725, 1728, 1729, 1730, 1731, 1732, 1733, 1735], 10: [1006, 1007, 1023, 1027, 1036, 1040, 1065, 1071, 1081, 1086, 1090, 1095, 1102, 1108, 1113, 1116, 1122, 1124, 1125, 1126, 1135, 1140, 1145, 1162, 1184, 1191, 1193, 1196, 1204, 1205, 1206, 1209, 1212, 1217, 1218, 1219, 1222, 1232, 1255, 1261, 1262, 1274, 1299, 1303, 1314, 1323, 1329, 1336, 1337, 1349, 1351, 1393, 1394, 1403, 1421, 1431, 1432, 1437, 1439, 1445, 1446, 1462, 1480, 1484, 1488, 1502, 1517, 1518, 1521, 1536, 1547, 1551, 1557, 1562, 1575, 1609, 1613, 1614, 1615, 1644, 1645, 1666, 1687, 1694, 1707, 1711, 1714, 1720, 1722]}\n",
      "{1000: 7, 1001: 0, 1002: 3, 1003: 7, 1004: 2, 1005: 9, 1006: 10, 1007: 10, 1008: 9, 1009: 0, 1010: 9, 1011: 9, 1012: 4, 1013: 3, 1014: 7, 1015: 1, 1016: 2, 1017: 9, 1018: 4, 1019: 0, 1020: 5, 1021: 3, 1022: 5, 1023: 10, 1024: 1, 1025: 6, 1026: 3, 1027: 10, 1028: 6, 1029: 3, 1030: 5, 1031: 2, 1032: 9, 1033: 3, 1034: 8, 1035: 9, 1036: 10, 1037: 0, 1038: 0, 1039: 2, 1040: 10, 1041: 5, 1042: 8, 1043: 2, 1044: 2, 1045: 2, 1046: 8, 1047: 9, 1048: 1, 1049: 9, 1050: 3, 1051: 2, 1052: 7, 1053: 5, 1054: 9, 1055: 1, 1056: 2, 1057: 2, 1058: 9, 1059: 5, 1060: 3, 1061: 3, 1062: 9, 1063: 5, 1064: 6, 1065: 10, 1066: 9, 1067: 1, 1068: 2, 1069: 9, 1070: 0, 1071: 10, 1072: 1, 1073: 7, 1074: 8, 1075: 2, 1076: 5, 1077: 9, 1078: 3, 1079: 2, 1080: 9, 1081: 10, 1082: 2, 1083: 9, 1084: 3, 1085: 4, 1086: 10, 1087: 9, 1088: 3, 1089: 3, 1090: 10, 1091: 9, 1092: 7, 1093: 2, 1094: 0, 1095: 10, 1096: 2, 1097: 2, 1098: 9, 1099: 6, 1100: 2, 1101: 5, 1102: 10, 1103: 2, 1104: 5, 1105: 2, 1106: 6, 1107: 1, 1108: 10, 1109: 6, 1110: 9, 1111: 9, 1112: 2, 1113: 10, 1114: 3, 1115: 5, 1116: 10, 1117: 2, 1118: 5, 1119: 2, 1120: 3, 1121: 2, 1122: 10, 1123: 2, 1124: 10, 1125: 10, 1126: 10, 1127: 5, 1128: 5, 1129: 4, 1130: 9, 1131: 2, 1132: 0, 1133: 2, 1134: 7, 1135: 10, 1136: 2, 1137: 9, 1138: 9, 1139: 5, 1140: 10, 1141: 7, 1142: 3, 1143: 9, 1144: 1, 1145: 10, 1146: 4, 1147: 1, 1148: 6, 1149: 9, 1150: 3, 1151: 9, 1152: 3, 1153: 5, 1154: 2, 1155: 7, 1156: 9, 1157: 8, 1158: 9, 1159: 6, 1160: 3, 1161: 2, 1162: 10, 1163: 2, 1164: 7, 1165: 6, 1166: 2, 1167: 9, 1168: 9, 1169: 9, 1170: 7, 1171: 6, 1172: 5, 1173: 9, 1174: 9, 1175: 0, 1176: 3, 1177: 0, 1178: 2, 1179: 2, 1180: 3, 1181: 3, 1182: 6, 1183: 9, 1184: 10, 1185: 0, 1186: 9, 1187: 7, 1188: 3, 1189: 6, 1190: 6, 1191: 10, 1192: 8, 1193: 10, 1194: 9, 1195: 9, 1196: 10, 1197: 3, 1198: 3, 1199: 9, 1200: 8, 1201: 2, 1202: 2, 1203: 7, 1204: 10, 1205: 10, 1206: 10, 1207: 3, 1208: 6, 1209: 10, 1210: 7, 1211: 6, 1212: 10, 1213: 9, 1214: 9, 1215: 0, 1216: 7, 1217: 10, 1218: 10, 1219: 10, 1220: 2, 1221: 5, 1222: 10, 1223: 9, 1224: 9, 1225: 5, 1226: 2, 1227: 7, 1228: 7, 1229: 9, 1230: 0, 1231: 6, 1232: 10, 1233: 9, 1234: 9, 1235: 3, 1236: 9, 1237: 7, 1238: 3, 1239: 7, 1240: 4, 1241: 3, 1242: 9, 1243: 2, 1244: 7, 1245: 3, 1246: 6, 1247: 8, 1248: 9, 1249: 8, 1250: 5, 1251: 0, 1252: 3, 1253: 7, 1254: 2, 1255: 10, 1256: 2, 1257: 7, 1258: 5, 1259: 9, 1260: 3, 1261: 10, 1262: 10, 1263: 3, 1264: 9, 1265: 9, 1266: 0, 1267: 3, 1268: 2, 1269: 5, 1270: 7, 1271: 7, 1272: 3, 1273: 9, 1274: 10, 1275: 4, 1276: 8, 1277: 5, 1278: 7, 1279: 7, 1280: 3, 1281: 9, 1282: 2, 1283: 7, 1284: 6, 1285: 2, 1286: 3, 1287: 2, 1288: 2, 1289: 7, 1290: 2, 1291: 9, 1292: 2, 1293: 7, 1294: 5, 1295: 1, 1296: 7, 1297: 9, 1298: 3, 1299: 10, 1300: 6, 1301: 2, 1302: 1, 1303: 10, 1304: 4, 1305: 6, 1306: 9, 1307: 8, 1308: 0, 1309: 5, 1310: 9, 1311: 5, 1312: 7, 1313: 4, 1314: 10, 1315: 9, 1316: 3, 1317: 9, 1318: 7, 1319: 3, 1320: 3, 1321: 5, 1322: 4, 1323: 10, 1324: 5, 1325: 0, 1326: 7, 1327: 3, 1328: 0, 1329: 10, 1330: 9, 1331: 7, 1332: 9, 1333: 6, 1334: 0, 1335: 2, 1336: 10, 1337: 10, 1338: 9, 1339: 3, 1340: 5, 1341: 8, 1342: 8, 1343: 2, 1344: 2, 1345: 2, 1346: 2, 1347: 0, 1348: 6, 1349: 10, 1350: 0, 1351: 10, 1352: 9, 1353: 9, 1354: 0, 1355: 3, 1356: 2, 1357: 3, 1358: 2, 1359: 7, 1360: 2, 1361: 3, 1362: 3, 1363: 3, 1364: 9, 1365: 9, 1366: 2, 1367: 9, 1368: 2, 1369: 7, 1370: 9, 1371: 2, 1372: 0, 1373: 9, 1374: 0, 1375: 9, 1376: 3, 1377: 1, 1378: 9, 1379: 2, 1380: 9, 1381: 9, 1382: 0, 1383: 0, 1384: 7, 1385: 9, 1386: 5, 1387: 7, 1388: 9, 1389: 9, 1390: 3, 1391: 2, 1392: 9, 1393: 10, 1394: 10, 1395: 2, 1396: 9, 1397: 5, 1398: 5, 1399: 9, 1400: 3, 1401: 6, 1402: 3, 1403: 10, 1404: 5, 1405: 0, 1406: 0, 1407: 2, 1408: 9, 1409: 9, 1410: 2, 1411: 3, 1412: 3, 1413: 9, 1414: 2, 1415: 2, 1416: 3, 1417: 2, 1418: 2, 1419: 1, 1420: 3, 1421: 10, 1422: 2, 1423: 2, 1424: 3, 1425: 2, 1426: 2, 1427: 7, 1428: 3, 1429: 5, 1430: 9, 1431: 10, 1432: 10, 1433: 9, 1434: 7, 1435: 2, 1436: 5, 1437: 10, 1438: 9, 1439: 10, 1440: 6, 1441: 0, 1442: 0, 1443: 9, 1444: 5, 1445: 10, 1446: 10, 1447: 0, 1448: 9, 1449: 0, 1450: 9, 1451: 9, 1452: 3, 1453: 9, 1454: 6, 1455: 2, 1456: 2, 1457: 7, 1458: 5, 1459: 3, 1460: 9, 1461: 1, 1462: 10, 1463: 3, 1464: 7, 1465: 7, 1466: 9, 1467: 9, 1468: 6, 1469: 3, 1470: 9, 1471: 1, 1472: 9, 1473: 2, 1474: 9, 1475: 0, 1476: 2, 1477: 8, 1478: 2, 1479: 7, 1480: 10, 1481: 9, 1482: 5, 1483: 2, 1484: 10, 1485: 8, 1486: 8, 1487: 9, 1488: 10, 1489: 1, 1490: 0, 1491: 3, 1492: 8, 1493: 0, 1494: 3, 1495: 9, 1496: 5, 1497: 2, 1498: 5, 1499: 5, 1500: 7, 1501: 2, 1502: 10, 1503: 2, 1504: 0, 1505: 2, 1506: 2, 1507: 4, 1508: 0, 1509: 2, 1510: 2, 1511: 2, 1512: 9, 1513: 8, 1514: 0, 1515: 2, 1516: 9, 1517: 10, 1518: 10, 1519: 9, 1520: 9, 1521: 10, 1522: 5, 1523: 6, 1524: 8, 1525: 8, 1526: 7, 1527: 8, 1528: 8, 1529: 9, 1530: 8, 1531: 0, 1532: 9, 1533: 2, 1534: 7, 1535: 9, 1536: 10, 1537: 9, 1538: 3, 1539: 5, 1540: 9, 1541: 2, 1542: 2, 1543: 3, 1544: 9, 1545: 9, 1546: 8, 1547: 10, 1548: 3, 1549: 7, 1550: 0, 1551: 10, 1552: 3, 1553: 5, 1554: 3, 1555: 7, 1556: 2, 1557: 10, 1558: 9, 1559: 9, 1560: 0, 1561: 9, 1562: 10, 1563: 3, 1564: 9, 1565: 2, 1566: 9, 1567: 5, 1568: 1, 1569: 2, 1570: 3, 1571: 6, 1572: 1, 1573: 9, 1574: 2, 1575: 10, 1576: 0, 1577: 9, 1578: 5, 1579: 2, 1580: 4, 1581: 9, 1582: 0, 1583: 8, 1584: 9, 1585: 2, 1586: 2, 1587: 6, 1588: 2, 1589: 4, 1590: 7, 1591: 1, 1592: 4, 1593: 9, 1594: 2, 1595: 2, 1596: 0, 1597: 2, 1598: 2, 1599: 9, 1600: 9, 1601: 2, 1602: 7, 1603: 2, 1604: 3, 1605: 1, 1606: 3, 1607: 9, 1608: 9, 1609: 10, 1610: 9, 1611: 0, 1612: 1, 1613: 10, 1614: 10, 1615: 10, 1616: 9, 1617: 2, 1618: 9, 1619: 8, 1620: 9, 1621: 3, 1622: 9, 1623: 9, 1624: 7, 1625: 2, 1626: 3, 1627: 9, 1628: 9, 1629: 9, 1630: 9, 1631: 7, 1632: 2, 1633: 1, 1634: 6, 1635: 9, 1636: 3, 1637: 3, 1638: 9, 1639: 4, 1640: 7, 1641: 3, 1642: 2, 1643: 7, 1644: 10, 1645: 10, 1646: 6, 1647: 9, 1648: 9, 1649: 0, 1650: 8, 1651: 2, 1652: 9, 1653: 2, 1654: 6, 1655: 2, 1656: 9, 1657: 3, 1658: 7, 1659: 2, 1660: 7, 1661: 3, 1662: 3, 1663: 9, 1664: 0, 1665: 2, 1666: 10, 1667: 6, 1668: 9, 1669: 6, 1670: 2, 1671: 9, 1672: 9, 1673: 2, 1674: 0, 1675: 2, 1676: 3, 1677: 9, 1678: 3, 1679: 9, 1680: 5, 1681: 9, 1682: 3, 1683: 3, 1684: 0, 1685: 7, 1686: 9, 1687: 10, 1688: 6, 1689: 0, 1690: 9, 1691: 9, 1692: 4, 1693: 9, 1694: 10, 1695: 0, 1696: 3, 1697: 0, 1698: 3, 1699: 4, 1700: 9, 1701: 4, 1702: 3, 1703: 5, 1704: 9, 1705: 2, 1706: 3, 1707: 10, 1708: 2, 1709: 7, 1710: 0, 1711: 10, 1712: 9, 1713: 1, 1714: 10, 1715: 2, 1716: 9, 1717: 2, 1718: 7, 1719: 2, 1720: 10, 1721: 5, 1722: 10, 1723: 9, 1724: 1, 1725: 9, 1726: 0, 1727: 3, 1728: 9, 1729: 9, 1730: 9, 1731: 9, 1732: 9, 1733: 9, 1734: 7, 1735: 9}\n"
     ]
    }
   ],
   "source": [
    "# prepare dictionary storeId to region\n",
    "# region_dict = {}\n",
    "store_dict = {}\n",
    "for i in range(0, 11):\n",
    "    region_dict[i] = []\n",
    "\n",
    "selected_features=[\n",
    "    'StoreID',\n",
    "    'Region']\n",
    "storeIDs = df.groupby(selected_features)\n",
    "for store_reg, data in storeIDs:\n",
    "#     region_dict[store_reg[1]].append(store_reg[0])\n",
    "    store_dict[store_reg[0]] = store_reg[1]\n",
    "    \n",
    "# print (region_dict)\n",
    "# print(store_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistemo i dati per regression tree\n",
    "## StoreID\n",
    "# df.drop('StoreID',axis=1) droppo dopo\n",
    "\n",
    "## StoreType\n",
    "df = pd.get_dummies(df, columns=['StoreType'], prefix='StoreType')\n",
    "\n",
    "## AssortmentType\n",
    "df = pd.get_dummies(df, columns=['AssortmentType'], prefix='AssortmentType')\n",
    "\n",
    "## Region\n",
    "df = pd.get_dummies(df, columns=['Region'], prefix='Region')\n",
    "\n",
    "## Events\n",
    "# No-Events (NaN) are considered as sunny days, with lowest value (0) on the events scale\n",
    "df['Events'] = df['Events'].fillna(0)\n",
    "df=df.replace({'Rain':1, 'Thunderstorm':1, 'Fog':1, 'Snow': 2, 'Fog-Rain': 2, 'Rain-Thunderstorm': 2, 'Rain-Snow':2, 'Fog-Snow':2, 'Fog-Rain-Snow':3, 'Rain-Hail':3, 'Snow-Hail':3, 'Rain-Snow-Hail':3, 'Fog-Rain-Hail':3, 'Fog-Thunderstorm':3, 'Fog-Rain-Thunderstorm':4, 'Fog-Snow-Hail':4, 'Fog-Rain-Snow-Hail':4, 'Rain-Snow-Thunderstorm':4, 'Rain-Hail-Thunderstorm':4, 'Fog-Rain-Hail-Thunderstorm':4, 'Rain-Snow-Hail-Thunderstorm':4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with NaN:\n",
      "Max_VisibilityKm\n",
      "Mean_VisibilityKm\n",
      "Min_VisibilitykM\n",
      "IsOpen_yesterday\n",
      "IsOpen_tomorrow\n",
      "IsHoliday_yesterday\n",
      "IsHoliday_tomorrow\n",
      "NumberOfSales_yesterday\n",
      "NumberOfSales_lastweek\n",
      "NumberOfSales_lastmonth\n"
     ]
    }
   ],
   "source": [
    "# Look for features with NaN values\n",
    "null_cols = find_nan_features(df)\n",
    "print('Features with NaN:')\n",
    "for col in null_cols:\n",
    "    print(col)\n",
    "    \n",
    "# drop all rows with NaN values\n",
    "df = remove_nan_rows(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide in several df based on storeid\n",
    "\n",
    "for i in range(1000, 1736):\n",
    "    store_df = df.loc[df['StoreID'] == i]\n",
    "    store_df.drop('StoreID',axis=1)\n",
    "    store_df.to_csv('./validation/' +str(i)+'.csv',index=False)\n",
    " \n",
    "# ## \n",
    "# #df_list.append(df.loc[df['StoreID'] == 1000]) \n",
    "# i = 1000\n",
    "# for store_df in df_list: \n",
    "# #     ## StoreID\n",
    "#     store_df.drop('StoreID',axis=1)\n",
    "#     store_df.to_csv('./validation/' +str(i)+'.csv',index=False)\n",
    "#     i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del store_df\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply train an validation to all store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1163814.3880000005, 470221.5560000001, 1672723.4440000001, 1377358.2479999994, 263085.7919999999, 656972.3720000004, 604803.7, 1393578.687999999, 421195.9759999998, 3653392.3120000027, 1279506.5200000003] [21367831.0, 8905037.0, 25986109.0, 41512390.0, 8366525.0, 17530999.0, 12060671.0, 23098370.0, 8910179.0, 64412870.0, 34773267.0]\n",
      "0.04772759227278169\n"
     ]
    }
   ],
   "source": [
    "train_fraction = 21/24\n",
    "region_num_list = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "region_den_list = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "for i in range (1000,1736):\n",
    "    print(\"Working on store: \"+str(i))\n",
    "# for i in range(1000,1010):\n",
    "    #retrieve dataset\n",
    "    df = pd.read_csv('./validation/'+str(i)+'.csv')\n",
    "    \n",
    "    # convert date to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "    \n",
    "    # split in train and validation\n",
    "    df_train, df_validation = split(df, train_fraction)\n",
    "    # store months\n",
    "    months = pd.DatetimeIndex(df_validation['Date']).month\n",
    "    # drop date\n",
    "    df_train = df_train.drop('Date', axis=1)\n",
    "    df_validation = df_validation.drop('Date', axis=1)\n",
    "    \n",
    "    # train model\n",
    "    X_train, y_train = get_x_y(df_train)\n",
    "    # # checking shapes\n",
    "    # print('X: ' + str(X_train.shape))\n",
    "    # print('y: ' + str(y_train.shape))\n",
    "    model = train_model(X_train, y_train)\n",
    "    \n",
    "    # evaluate model\n",
    "    X_val, y_val = get_x_y(df_validation)\n",
    "    # # checking shapes\n",
    "    # print('X: ' + str(X_val.shape))\n",
    "    # print('y: ' + str(y_val.shape))\n",
    "    \n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "#     new_x_val = X_val \n",
    "    X_val['Month'] = months\n",
    "#     new_x_val['StoreID'] = val_id\n",
    "    \n",
    "    del model\n",
    "    \n",
    "    # adjust shape\n",
    "    X_val = X_val.reset_index(drop=True)\n",
    "    y_pred = y_pred.tolist()\n",
    "    y_val = y_val.tolist()\n",
    "    \n",
    "    region = store_dict[i]           \n",
    "    for m in range(1,13):\n",
    "        sum_pred_month = 0\n",
    "        sum_actual_month = 0\n",
    "        indexes = X_val.index[X_val['Month'] == m].tolist()\n",
    "\n",
    "        for j in indexes:\n",
    "\n",
    "            sum_pred_month += y_pred[j]\n",
    "            sum_actual_month += y_val[j]\n",
    "\n",
    "        region_num_list[region] += abs(sum_actual_month - sum_pred_month)\n",
    "        region_den_list[region] += sum_actual_month    \n",
    "    \n",
    "# print(region_num_list,region_den_list)\n",
    "\n",
    "e_r = []\n",
    "for r in range(11):\n",
    "    e_r.append(region_num_list[r]/region_den_list[r])\n",
    "    \n",
    "\n",
    "print(sum(e_r)/len(e_r))\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result: 0.04772759227278169"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1163814.3880000005, 470221.5560000001, 1672723.4440000001, 1377358.2479999994, 263085.7919999999, 656972.3720000004, 604803.7, 1393578.687999999, 421195.9759999998, 3653392.3120000027, 1279506.5200000003]\n",
    "b = [21367831.0, 8905037.0, 25986109.0, 41512390.0, 8366525.0, 17530999.0, 12060671.0, 23098370.0, 8910179.0, 64412870.0, 34773267.0]\n",
    "for i in range(11):\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamining6",
   "language": "python",
   "name": "datamining6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
