{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load csvs to dataframe\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "len_test = len(df_test)\n",
    "\n",
    "# we need both for the temporal features\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show sample row\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing Values\n",
    "# cloud coverage: 0 if no events, 8 if events\n",
    "for row in range(len(df)):\n",
    "    if row % 10000 == 0:\n",
    "        clear_output()\n",
    "        print(\"Working on row {}\".format(row))\n",
    "    if np.isnan(df.loc[row, 'CloudCover']):\n",
    "        if df.loc[row, 'Events'] is np.nan:\n",
    "            df.loc[row, 'CloudCover'] = 0\n",
    "        else:\n",
    "            df.loc[row, 'CloudCover'] = 8\n",
    "\n",
    "# max gust speed = max wind speed\n",
    "df.Max_Gust_SpeedKm_h = df.Max_Gust_SpeedKm_h.fillna(df.Max_Wind_SpeedKm_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Date Features\n",
    "# convert date to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# add features\n",
    "# df['DayN']=df['Date'].dt.dayofyear    # non credo possa servire\n",
    "df['DayOfWeek']=df['Date'].dt.dayofweek\n",
    "df['Month']=df['Date'].dt.month\n",
    "df['Week']=df['Date'].dt.weekofyear\n",
    "df['Quarter']=df['Date'].dt.quarter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Temporal Features\n",
    "# create columns\n",
    "df['IsOpen_yesterday'] = np.empty(len(df))\n",
    "df['IsOpen_tomorrow'] = np.empty(len(df))\n",
    "df['IsHoliday_yesterday'] = np.empty(len(df))\n",
    "df['IsHoliday_tomorrow'] = np.empty(len(df))\n",
    "df['NumberOfSales_yesterday'] = np.empty(len(df))\n",
    "df['NumberOfSales_lastweek'] = np.empty(len(df))\n",
    "df['NumberOfSales_lastmonth'] = np.empty(len(df))\n",
    "\n",
    "for store in df.StoreID.unique():\n",
    "    clear_output()\n",
    "    print(\"Working on {}\".format(store))\n",
    "    temp = df.loc[df.StoreID == store]\n",
    "    # switch index to timestamps to make this easier\n",
    "    oldindex = temp.index\n",
    "    temp.index = temp['Date']\n",
    "    \n",
    "    temp['IsOpen_yesterday'] = temp.IsOpen.rolling(window='1d',closed='left', min_periods=1).sum()\n",
    "    temp['IsOpen_tomorrow'] = temp.IsOpen.rolling(window='1d',closed='left', min_periods=1).sum().shift(-2, '1d')\n",
    "    temp['IsHoliday_yesterday'] = temp.IsHoliday.rolling(window='1d',closed='left', min_periods=1).sum()\n",
    "    temp['IsHoliday_tomorrow'] = temp.IsHoliday.rolling(window='1d',closed='left', min_periods=1).sum().shift(-2, '1d')\n",
    "    temp['NumberOfSales_yesterday'] = temp.NumberOfSales.rolling(window='1d',closed='left', min_periods=1).sum()\n",
    "    temp['NumberOfSales_lastweek'] = temp.NumberOfSales.rolling(window='7d',closed='left', min_periods=1).sum()\n",
    "    temp['NumberOfSales_lastmonth'] = temp.NumberOfSales.rolling(window='30d',closed='left', min_periods=1).sum()\n",
    "    \n",
    "    # put it back in the dataframe\n",
    "    temp.index = oldindex\n",
    "    df.loc[df.StoreID == store] = temp\n",
    "    \n",
    "# Attenzione: i valori di tomorrow nel test sono sputtanati a NaN\n",
    "# vanno messi a mano qui o cambiato il modo di calcolo\n",
    "    \n",
    "# drop rows at the beginning where we have no past information\n",
    "# NB: possiamo fare a meno se togliamo quelle feature\n",
    "df = df.iloc[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding\n",
    "# nb: pd.get_dummies rimuove le colonne direttamente\n",
    "\n",
    "# ## StoreId\n",
    "# df = pd.get_dummies(df, columns=['StoreID'], prefix='StoreID')\n",
    "\n",
    " ## StoreType\n",
    "# df = pd.get_dummies(df, columns=['StoreType'], prefix='StoreType')\n",
    "\n",
    " ## AssortmentType\n",
    "# df = pd.get_dummies(df, columns=['AssortmentType'], prefix='AssortmentType')\n",
    "\n",
    "# ## Region\n",
    "# df = pd.get_dummies(df, columns=['Region'], prefix='Region')\n",
    "\n",
    "# ## Events\n",
    "# df = pd.get_dummies(df, columns=['Events'], prefix='Events', dummy_na=True)\n",
    "### inutile se possiamo usare categorie con decision tree\n",
    "\n",
    "# numeric features to categories (strings)\n",
    "# df.StoreID = df.StoreID.astype(str)\n",
    "# df.Region = df.Region.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns\n",
    "df = df.drop('Date', axis=1)\n",
    "df = df.drop('NumberOfCustomers', axis=1)  \n",
    "df = df.drop('WindDirDegrees', axis=1)\n",
    "\n",
    "# questi non cambiano mai, teniamo regione e population\n",
    "df = df.drop('Region_AreaKM2', axis=1)\n",
    "df = df.drop('Region_GDP', axis=1)\n",
    "#df = df.drop('Region_PopulationK', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with IsOpen = 0\n",
    "# -> number of sales is always = 0 \n",
    "df = df[df.IsOpen == 1]\n",
    "df = df.drop('IsOpen', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save preprocessed data\n",
    "df[:-len_test].to_csv('preprocessed_train.csv',index=False)\n",
    "df[-len_test:].to_csv('preprocessed_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REMEMBER\n",
    "# le sales di testing vanno aggiunte e sistemate a runtime"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
