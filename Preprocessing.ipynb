{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load csvs to dataframe\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "len_test = len(df_test)\n",
    "\n",
    "# we need both for the temporal features\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AssortmentType</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>Date</th>\n",
       "      <th>Events</th>\n",
       "      <th>HasPromotions</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>IsOpen</th>\n",
       "      <th>Max_Dew_PointC</th>\n",
       "      <th>Max_Gust_SpeedKm_h</th>\n",
       "      <th>Max_Humidity</th>\n",
       "      <th>...</th>\n",
       "      <th>NumberOfCustomers</th>\n",
       "      <th>NumberOfSales</th>\n",
       "      <th>Precipitationmm</th>\n",
       "      <th>Region</th>\n",
       "      <th>Region_AreaKM2</th>\n",
       "      <th>Region_GDP</th>\n",
       "      <th>Region_PopulationK</th>\n",
       "      <th>StoreID</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>WindDirDegrees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>General</td>\n",
       "      <td>8.0</td>\n",
       "      <td>01/03/2016</td>\n",
       "      <td>Rain-Snow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>495.0</td>\n",
       "      <td>5676.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9643</td>\n",
       "      <td>17130</td>\n",
       "      <td>2770</td>\n",
       "      <td>1000</td>\n",
       "      <td>Hyper Market</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>General</td>\n",
       "      <td>8.0</td>\n",
       "      <td>02/03/2016</td>\n",
       "      <td>Snow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>608.0</td>\n",
       "      <td>8111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9643</td>\n",
       "      <td>17130</td>\n",
       "      <td>2770</td>\n",
       "      <td>1000</td>\n",
       "      <td>Hyper Market</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>General</td>\n",
       "      <td>8.0</td>\n",
       "      <td>04/03/2016</td>\n",
       "      <td>Rain</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>665.0</td>\n",
       "      <td>8300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9643</td>\n",
       "      <td>17130</td>\n",
       "      <td>2770</td>\n",
       "      <td>1000</td>\n",
       "      <td>Hyper Market</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>General</td>\n",
       "      <td>6.0</td>\n",
       "      <td>05/03/2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>630.0</td>\n",
       "      <td>7154.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9643</td>\n",
       "      <td>17130</td>\n",
       "      <td>2770</td>\n",
       "      <td>1000</td>\n",
       "      <td>Hyper Market</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General</td>\n",
       "      <td>6.0</td>\n",
       "      <td>06/03/2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9643</td>\n",
       "      <td>17130</td>\n",
       "      <td>2770</td>\n",
       "      <td>1000</td>\n",
       "      <td>Hyper Market</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  AssortmentType  CloudCover        Date     Events  HasPromotions  IsHoliday  \\\n",
       "0        General         8.0  01/03/2016  Rain-Snow              0          0   \n",
       "1        General         8.0  02/03/2016       Snow              0          0   \n",
       "2        General         8.0  04/03/2016       Rain              0          0   \n",
       "3        General         6.0  05/03/2016        NaN              0          0   \n",
       "4        General         6.0  06/03/2016        NaN              0          0   \n",
       "\n",
       "   IsOpen  Max_Dew_PointC  Max_Gust_SpeedKm_h  Max_Humidity       ...        \\\n",
       "0       1               1                 NaN           100       ...         \n",
       "1       1               0                 NaN            87       ...         \n",
       "2       1               0                 NaN            81       ...         \n",
       "3       1              -3                 NaN            80       ...         \n",
       "4       0               0                 NaN            93       ...         \n",
       "\n",
       "   NumberOfCustomers  NumberOfSales  Precipitationmm  Region  Region_AreaKM2  \\\n",
       "0              495.0         5676.0              0.0       7            9643   \n",
       "1              608.0         8111.0              0.0       7            9643   \n",
       "2              665.0         8300.0              0.0       7            9643   \n",
       "3              630.0         7154.0              0.0       7            9643   \n",
       "4                0.0            0.0              0.0       7            9643   \n",
       "\n",
       "   Region_GDP  Region_PopulationK  StoreID     StoreType  WindDirDegrees  \n",
       "0       17130                2770     1000  Hyper Market              23  \n",
       "1       17130                2770     1000  Hyper Market              56  \n",
       "2       17130                2770     1000  Hyper Market              22  \n",
       "3       17130                2770     1000  Hyper Market             108  \n",
       "4       17130                2770     1000  Hyper Market              46  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AssortmentType                     General\n",
       "CloudCover                               8\n",
       "Date                            01/03/2016\n",
       "Events                           Rain-Snow\n",
       "HasPromotions                            0\n",
       "IsHoliday                                0\n",
       "IsOpen                                   1\n",
       "Max_Dew_PointC                           1\n",
       "Max_Gust_SpeedKm_h                     NaN\n",
       "Max_Humidity                           100\n",
       "Max_Sea_Level_PressurehPa             1032\n",
       "Max_TemperatureC                         2\n",
       "Max_VisibilityKm                        19\n",
       "Max_Wind_SpeedKm_h                      21\n",
       "Mean_Dew_PointC                         -1\n",
       "Mean_Humidity                           82\n",
       "Mean_Sea_Level_PressurehPa            1030\n",
       "Mean_TemperatureC                        1\n",
       "Mean_VisibilityKm                       11\n",
       "Mean_Wind_SpeedKm_h                     16\n",
       "Min_Dew_PointC                          -2\n",
       "Min_Humidity                            70\n",
       "Min_Sea_Level_PressurehPa             1029\n",
       "Min_TemperatureC                         1\n",
       "Min_VisibilitykM                         6\n",
       "NearestCompetitor                      326\n",
       "NumberOfCustomers                      495\n",
       "NumberOfSales                         5676\n",
       "Precipitationmm                          0\n",
       "Region                                   7\n",
       "Region_AreaKM2                        9643\n",
       "Region_GDP                           17130\n",
       "Region_PopulationK                    2770\n",
       "StoreID                               1000\n",
       "StoreType                     Hyper Market\n",
       "WindDirDegrees                          23\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show sample row\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on row 0\n",
      "Working on row 10000\n",
      "Working on row 20000\n",
      "Working on row 30000\n",
      "Working on row 40000\n",
      "Working on row 50000\n",
      "Working on row 60000\n",
      "Working on row 70000\n",
      "Working on row 80000\n",
      "Working on row 90000\n",
      "Working on row 100000\n",
      "Working on row 110000\n",
      "Working on row 120000\n",
      "Working on row 130000\n",
      "Working on row 140000\n",
      "Working on row 150000\n",
      "Working on row 160000\n",
      "Working on row 170000\n",
      "Working on row 180000\n",
      "Working on row 190000\n",
      "Working on row 200000\n",
      "Working on row 210000\n",
      "Working on row 220000\n",
      "Working on row 230000\n",
      "Working on row 240000\n",
      "Working on row 250000\n",
      "Working on row 260000\n",
      "Working on row 270000\n",
      "Working on row 280000\n",
      "Working on row 290000\n",
      "Working on row 300000\n",
      "Working on row 310000\n",
      "Working on row 320000\n",
      "Working on row 330000\n",
      "Working on row 340000\n",
      "Working on row 350000\n",
      "Working on row 360000\n",
      "Working on row 370000\n",
      "Working on row 380000\n",
      "Working on row 390000\n",
      "Working on row 400000\n",
      "Working on row 410000\n",
      "Working on row 420000\n",
      "Working on row 430000\n",
      "Working on row 440000\n",
      "Working on row 450000\n",
      "Working on row 460000\n",
      "Working on row 470000\n",
      "Working on row 480000\n",
      "Working on row 490000\n",
      "Working on row 500000\n",
      "Working on row 510000\n",
      "Working on row 520000\n",
      "Working on row 530000\n",
      "Working on row 540000\n",
      "Working on row 550000\n",
      "Working on row 560000\n"
     ]
    }
   ],
   "source": [
    "## Missing Values\n",
    "# cloud coverage: 0 if no events, 8 if events\n",
    "for row in range(len(df)):\n",
    "    if row % 10000 == 0:\n",
    "        print(\"Working on row {}\".format(row))\n",
    "    if np.isnan(df.loc[row, 'CloudCover']):\n",
    "        if df.loc[row, 'Events'] is np.nan:\n",
    "            df.loc[row, 'CloudCover'] = 0\n",
    "        else:\n",
    "            df.loc[row, 'CloudCover'] = 8\n",
    "\n",
    "# max gust speed = max wind speed\n",
    "df.Max_Gust_SpeedKm_h = df.Max_Gust_SpeedKm_h.fillna(df.Max_Wind_SpeedKm_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Date Features\n",
    "# convert date to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# add features\n",
    "# df['DayN']=df['Date'].dt.dayofyear    # non credo possa servire\n",
    "df['DayOfWeek']=df['Date'].dt.dayofweek\n",
    "df['Month']=df['Date'].dt.month\n",
    "df['Week']=df['Date'].dt.weekofyear\n",
    "df['Quarter']=df['Date'].dt.quarter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feder\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\feder\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\feder\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\feder\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\feder\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\feder\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\feder\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 1001\n",
      "Working on 1002\n",
      "Working on 1003\n",
      "Working on 1004\n",
      "Working on 1005\n",
      "Working on 1006\n",
      "Working on 1007\n",
      "Working on 1008\n",
      "Working on 1009\n",
      "Working on 1010\n",
      "Working on 1011\n",
      "Working on 1012\n",
      "Working on 1013\n",
      "Working on 1014\n",
      "Working on 1015\n",
      "Working on 1016\n",
      "Working on 1017\n",
      "Working on 1018\n",
      "Working on 1019\n",
      "Working on 1020\n",
      "Working on 1021\n",
      "Working on 1022\n",
      "Working on 1023\n",
      "Working on 1024\n",
      "Working on 1025\n",
      "Working on 1026\n",
      "Working on 1027\n",
      "Working on 1028\n",
      "Working on 1029\n",
      "Working on 1030\n",
      "Working on 1031\n",
      "Working on 1032\n",
      "Working on 1033\n",
      "Working on 1034\n",
      "Working on 1035\n",
      "Working on 1036\n",
      "Working on 1037\n",
      "Working on 1038\n",
      "Working on 1039\n",
      "Working on 1040\n",
      "Working on 1041\n",
      "Working on 1042\n",
      "Working on 1043\n",
      "Working on 1044\n",
      "Working on 1045\n",
      "Working on 1046\n",
      "Working on 1047\n",
      "Working on 1048\n",
      "Working on 1049\n",
      "Working on 1050\n",
      "Working on 1051\n",
      "Working on 1052\n",
      "Working on 1053\n",
      "Working on 1054\n",
      "Working on 1055\n",
      "Working on 1056\n",
      "Working on 1057\n",
      "Working on 1058\n",
      "Working on 1059\n",
      "Working on 1060\n",
      "Working on 1061\n",
      "Working on 1062\n",
      "Working on 1063\n",
      "Working on 1064\n",
      "Working on 1065\n",
      "Working on 1066\n",
      "Working on 1067\n",
      "Working on 1068\n",
      "Working on 1069\n",
      "Working on 1070\n",
      "Working on 1071\n",
      "Working on 1072\n",
      "Working on 1073\n",
      "Working on 1074\n",
      "Working on 1075\n",
      "Working on 1076\n",
      "Working on 1077\n",
      "Working on 1078\n",
      "Working on 1079\n",
      "Working on 1080\n",
      "Working on 1081\n",
      "Working on 1082\n",
      "Working on 1083\n",
      "Working on 1084\n",
      "Working on 1085\n",
      "Working on 1086\n",
      "Working on 1087\n",
      "Working on 1088\n",
      "Working on 1089\n",
      "Working on 1090\n",
      "Working on 1091\n",
      "Working on 1092\n",
      "Working on 1093\n",
      "Working on 1094\n",
      "Working on 1095\n",
      "Working on 1096\n",
      "Working on 1097\n",
      "Working on 1098\n",
      "Working on 1099\n",
      "Working on 1100\n",
      "Working on 1101\n",
      "Working on 1102\n",
      "Working on 1103\n",
      "Working on 1104\n",
      "Working on 1105\n",
      "Working on 1106\n",
      "Working on 1107\n",
      "Working on 1108\n",
      "Working on 1109\n",
      "Working on 1110\n",
      "Working on 1111\n",
      "Working on 1112\n",
      "Working on 1113\n",
      "Working on 1114\n",
      "Working on 1115\n",
      "Working on 1116\n",
      "Working on 1117\n",
      "Working on 1118\n",
      "Working on 1119\n",
      "Working on 1120\n",
      "Working on 1121\n",
      "Working on 1122\n",
      "Working on 1123\n",
      "Working on 1124\n",
      "Working on 1125\n",
      "Working on 1126\n",
      "Working on 1127\n",
      "Working on 1128\n",
      "Working on 1129\n",
      "Working on 1130\n",
      "Working on 1131\n",
      "Working on 1132\n",
      "Working on 1133\n",
      "Working on 1134\n",
      "Working on 1135\n",
      "Working on 1136\n",
      "Working on 1137\n",
      "Working on 1138\n",
      "Working on 1139\n",
      "Working on 1140\n",
      "Working on 1141\n",
      "Working on 1142\n",
      "Working on 1143\n",
      "Working on 1144\n",
      "Working on 1145\n",
      "Working on 1146\n",
      "Working on 1147\n",
      "Working on 1148\n",
      "Working on 1149\n",
      "Working on 1150\n",
      "Working on 1151\n",
      "Working on 1152\n",
      "Working on 1153\n",
      "Working on 1154\n",
      "Working on 1155\n",
      "Working on 1156\n",
      "Working on 1157\n",
      "Working on 1158\n",
      "Working on 1159\n",
      "Working on 1160\n",
      "Working on 1161\n",
      "Working on 1162\n",
      "Working on 1163\n",
      "Working on 1164\n",
      "Working on 1165\n",
      "Working on 1166\n",
      "Working on 1167\n",
      "Working on 1168\n",
      "Working on 1169\n",
      "Working on 1170\n",
      "Working on 1171\n",
      "Working on 1172\n",
      "Working on 1173\n",
      "Working on 1174\n",
      "Working on 1175\n",
      "Working on 1176\n",
      "Working on 1177\n",
      "Working on 1178\n",
      "Working on 1179\n",
      "Working on 1180\n",
      "Working on 1181\n",
      "Working on 1182\n",
      "Working on 1183\n",
      "Working on 1184\n",
      "Working on 1185\n",
      "Working on 1186\n",
      "Working on 1187\n",
      "Working on 1188\n",
      "Working on 1189\n",
      "Working on 1190\n",
      "Working on 1191\n",
      "Working on 1192\n",
      "Working on 1193\n",
      "Working on 1194\n",
      "Working on 1195\n",
      "Working on 1196\n",
      "Working on 1197\n",
      "Working on 1198\n",
      "Working on 1199\n",
      "Working on 1200\n",
      "Working on 1201\n",
      "Working on 1202\n",
      "Working on 1203\n",
      "Working on 1204\n",
      "Working on 1205\n",
      "Working on 1206\n",
      "Working on 1207\n",
      "Working on 1208\n",
      "Working on 1209\n",
      "Working on 1210\n",
      "Working on 1211\n",
      "Working on 1212\n",
      "Working on 1213\n",
      "Working on 1214\n",
      "Working on 1215\n",
      "Working on 1216\n",
      "Working on 1217\n",
      "Working on 1218\n",
      "Working on 1219\n",
      "Working on 1220\n",
      "Working on 1221\n",
      "Working on 1222\n",
      "Working on 1223\n",
      "Working on 1224\n",
      "Working on 1225\n",
      "Working on 1226\n",
      "Working on 1227\n",
      "Working on 1228\n",
      "Working on 1229\n",
      "Working on 1230\n",
      "Working on 1231\n",
      "Working on 1232\n",
      "Working on 1233\n",
      "Working on 1234\n",
      "Working on 1235\n",
      "Working on 1236\n",
      "Working on 1237\n",
      "Working on 1238\n",
      "Working on 1239\n",
      "Working on 1240\n",
      "Working on 1241\n",
      "Working on 1242\n",
      "Working on 1243\n",
      "Working on 1244\n",
      "Working on 1245\n",
      "Working on 1246\n",
      "Working on 1247\n",
      "Working on 1248\n",
      "Working on 1249\n",
      "Working on 1250\n",
      "Working on 1251\n",
      "Working on 1252\n",
      "Working on 1253\n",
      "Working on 1254\n",
      "Working on 1255\n",
      "Working on 1256\n",
      "Working on 1257\n",
      "Working on 1258\n",
      "Working on 1259\n",
      "Working on 1260\n",
      "Working on 1261\n",
      "Working on 1262\n",
      "Working on 1263\n",
      "Working on 1264\n",
      "Working on 1265\n",
      "Working on 1266\n",
      "Working on 1267\n",
      "Working on 1268\n",
      "Working on 1269\n",
      "Working on 1270\n",
      "Working on 1271\n",
      "Working on 1272\n",
      "Working on 1273\n",
      "Working on 1274\n",
      "Working on 1275\n",
      "Working on 1276\n",
      "Working on 1277\n",
      "Working on 1278\n",
      "Working on 1279\n",
      "Working on 1280\n",
      "Working on 1281\n",
      "Working on 1282\n",
      "Working on 1283\n",
      "Working on 1284\n",
      "Working on 1285\n",
      "Working on 1286\n",
      "Working on 1287\n",
      "Working on 1288\n",
      "Working on 1289\n",
      "Working on 1290\n",
      "Working on 1291\n",
      "Working on 1292\n",
      "Working on 1293\n",
      "Working on 1294\n",
      "Working on 1295\n",
      "Working on 1296\n",
      "Working on 1297\n",
      "Working on 1298\n",
      "Working on 1299\n",
      "Working on 1300\n",
      "Working on 1301\n",
      "Working on 1302\n",
      "Working on 1303\n",
      "Working on 1304\n",
      "Working on 1305\n",
      "Working on 1306\n",
      "Working on 1307\n",
      "Working on 1308\n",
      "Working on 1309\n",
      "Working on 1310\n",
      "Working on 1311\n",
      "Working on 1312\n",
      "Working on 1313\n",
      "Working on 1314\n",
      "Working on 1315\n",
      "Working on 1316\n",
      "Working on 1317\n",
      "Working on 1318\n",
      "Working on 1319\n",
      "Working on 1320\n",
      "Working on 1321\n",
      "Working on 1322\n",
      "Working on 1323\n",
      "Working on 1324\n",
      "Working on 1325\n",
      "Working on 1326\n",
      "Working on 1327\n",
      "Working on 1328\n",
      "Working on 1329\n",
      "Working on 1330\n",
      "Working on 1331\n",
      "Working on 1332\n",
      "Working on 1333\n",
      "Working on 1334\n",
      "Working on 1335\n",
      "Working on 1336\n",
      "Working on 1337\n",
      "Working on 1338\n",
      "Working on 1339\n",
      "Working on 1340\n",
      "Working on 1341\n",
      "Working on 1342\n",
      "Working on 1343\n",
      "Working on 1344\n",
      "Working on 1345\n",
      "Working on 1346\n",
      "Working on 1347\n",
      "Working on 1348\n",
      "Working on 1349\n",
      "Working on 1350\n",
      "Working on 1351\n",
      "Working on 1352\n",
      "Working on 1353\n",
      "Working on 1354\n",
      "Working on 1355\n",
      "Working on 1356\n",
      "Working on 1357\n",
      "Working on 1358\n",
      "Working on 1359\n",
      "Working on 1360\n",
      "Working on 1361\n",
      "Working on 1362\n",
      "Working on 1363\n",
      "Working on 1364\n",
      "Working on 1365\n",
      "Working on 1366\n",
      "Working on 1367\n",
      "Working on 1368\n",
      "Working on 1369\n",
      "Working on 1370\n",
      "Working on 1371\n",
      "Working on 1372\n",
      "Working on 1373\n",
      "Working on 1374\n",
      "Working on 1375\n",
      "Working on 1376\n",
      "Working on 1377\n",
      "Working on 1378\n",
      "Working on 1379\n",
      "Working on 1380\n",
      "Working on 1381\n",
      "Working on 1382\n",
      "Working on 1383\n",
      "Working on 1384\n",
      "Working on 1385\n",
      "Working on 1386\n",
      "Working on 1387\n",
      "Working on 1388\n",
      "Working on 1389\n",
      "Working on 1390\n",
      "Working on 1391\n",
      "Working on 1392\n",
      "Working on 1393\n",
      "Working on 1394\n",
      "Working on 1395\n",
      "Working on 1396\n",
      "Working on 1397\n",
      "Working on 1398\n",
      "Working on 1399\n",
      "Working on 1400\n",
      "Working on 1401\n",
      "Working on 1402\n",
      "Working on 1403\n",
      "Working on 1404\n",
      "Working on 1405\n",
      "Working on 1406\n",
      "Working on 1407\n",
      "Working on 1408\n",
      "Working on 1409\n",
      "Working on 1410\n",
      "Working on 1411\n",
      "Working on 1412\n",
      "Working on 1413\n",
      "Working on 1414\n",
      "Working on 1415\n",
      "Working on 1416\n",
      "Working on 1417\n",
      "Working on 1418\n",
      "Working on 1419\n",
      "Working on 1420\n",
      "Working on 1421\n",
      "Working on 1422\n",
      "Working on 1423\n",
      "Working on 1424\n",
      "Working on 1425\n",
      "Working on 1426\n",
      "Working on 1427\n",
      "Working on 1428\n",
      "Working on 1429\n",
      "Working on 1430\n",
      "Working on 1431\n",
      "Working on 1432\n",
      "Working on 1433\n",
      "Working on 1434\n",
      "Working on 1435\n",
      "Working on 1436\n",
      "Working on 1437\n",
      "Working on 1438\n",
      "Working on 1439\n",
      "Working on 1440\n",
      "Working on 1441\n",
      "Working on 1442\n",
      "Working on 1443\n",
      "Working on 1444\n",
      "Working on 1445\n",
      "Working on 1446\n",
      "Working on 1447\n",
      "Working on 1448\n",
      "Working on 1449\n",
      "Working on 1450\n",
      "Working on 1451\n",
      "Working on 1452\n",
      "Working on 1453\n",
      "Working on 1454\n",
      "Working on 1455\n",
      "Working on 1456\n",
      "Working on 1457\n",
      "Working on 1458\n",
      "Working on 1459\n",
      "Working on 1460\n",
      "Working on 1461\n",
      "Working on 1462\n",
      "Working on 1463\n",
      "Working on 1464\n",
      "Working on 1465\n",
      "Working on 1466\n",
      "Working on 1467\n",
      "Working on 1468\n",
      "Working on 1469\n",
      "Working on 1470\n",
      "Working on 1471\n",
      "Working on 1472\n",
      "Working on 1473\n",
      "Working on 1474\n",
      "Working on 1475\n",
      "Working on 1476\n",
      "Working on 1477\n",
      "Working on 1478\n",
      "Working on 1479\n",
      "Working on 1480\n",
      "Working on 1481\n",
      "Working on 1482\n",
      "Working on 1483\n",
      "Working on 1484\n",
      "Working on 1485\n",
      "Working on 1486\n",
      "Working on 1487\n",
      "Working on 1488\n",
      "Working on 1489\n",
      "Working on 1490\n",
      "Working on 1491\n",
      "Working on 1492\n",
      "Working on 1493\n",
      "Working on 1494\n",
      "Working on 1495\n",
      "Working on 1496\n",
      "Working on 1497\n",
      "Working on 1498\n",
      "Working on 1499\n",
      "Working on 1500\n",
      "Working on 1501\n",
      "Working on 1502\n",
      "Working on 1503\n",
      "Working on 1504\n",
      "Working on 1505\n",
      "Working on 1506\n",
      "Working on 1507\n",
      "Working on 1508\n",
      "Working on 1509\n",
      "Working on 1510\n",
      "Working on 1511\n",
      "Working on 1512\n",
      "Working on 1513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 1514\n",
      "Working on 1515\n",
      "Working on 1516\n",
      "Working on 1517\n",
      "Working on 1518\n",
      "Working on 1519\n",
      "Working on 1520\n",
      "Working on 1521\n",
      "Working on 1522\n",
      "Working on 1523\n",
      "Working on 1524\n",
      "Working on 1525\n",
      "Working on 1526\n",
      "Working on 1527\n",
      "Working on 1528\n",
      "Working on 1529\n",
      "Working on 1530\n",
      "Working on 1531\n",
      "Working on 1532\n",
      "Working on 1533\n",
      "Working on 1534\n",
      "Working on 1535\n",
      "Working on 1536\n",
      "Working on 1537\n",
      "Working on 1538\n",
      "Working on 1539\n",
      "Working on 1540\n",
      "Working on 1541\n",
      "Working on 1542\n",
      "Working on 1543\n",
      "Working on 1544\n",
      "Working on 1545\n",
      "Working on 1546\n",
      "Working on 1547\n",
      "Working on 1548\n",
      "Working on 1549\n",
      "Working on 1550\n",
      "Working on 1551\n",
      "Working on 1552\n",
      "Working on 1553\n",
      "Working on 1554\n",
      "Working on 1555\n",
      "Working on 1556\n",
      "Working on 1557\n",
      "Working on 1558\n",
      "Working on 1559\n",
      "Working on 1560\n",
      "Working on 1561\n",
      "Working on 1562\n",
      "Working on 1563\n",
      "Working on 1564\n",
      "Working on 1565\n",
      "Working on 1566\n",
      "Working on 1567\n",
      "Working on 1568\n",
      "Working on 1569\n",
      "Working on 1570\n",
      "Working on 1571\n",
      "Working on 1572\n",
      "Working on 1573\n",
      "Working on 1574\n",
      "Working on 1575\n",
      "Working on 1576\n",
      "Working on 1577\n",
      "Working on 1578\n",
      "Working on 1579\n",
      "Working on 1580\n",
      "Working on 1581\n",
      "Working on 1582\n",
      "Working on 1583\n",
      "Working on 1584\n",
      "Working on 1585\n",
      "Working on 1586\n",
      "Working on 1587\n",
      "Working on 1588\n",
      "Working on 1589\n",
      "Working on 1590\n",
      "Working on 1591\n",
      "Working on 1592\n",
      "Working on 1593\n",
      "Working on 1594\n",
      "Working on 1595\n",
      "Working on 1596\n",
      "Working on 1597\n",
      "Working on 1598\n",
      "Working on 1599\n",
      "Working on 1600\n",
      "Working on 1601\n",
      "Working on 1602\n",
      "Working on 1603\n",
      "Working on 1604\n",
      "Working on 1605\n",
      "Working on 1606\n",
      "Working on 1607\n",
      "Working on 1608\n",
      "Working on 1609\n",
      "Working on 1610\n",
      "Working on 1611\n",
      "Working on 1612\n",
      "Working on 1613\n",
      "Working on 1614\n",
      "Working on 1615\n",
      "Working on 1616\n",
      "Working on 1617\n",
      "Working on 1618\n",
      "Working on 1619\n",
      "Working on 1620\n",
      "Working on 1621\n",
      "Working on 1622\n",
      "Working on 1623\n",
      "Working on 1624\n",
      "Working on 1625\n",
      "Working on 1626\n",
      "Working on 1627\n",
      "Working on 1628\n",
      "Working on 1629\n",
      "Working on 1630\n",
      "Working on 1631\n",
      "Working on 1632\n",
      "Working on 1633\n",
      "Working on 1634\n",
      "Working on 1635\n",
      "Working on 1636\n",
      "Working on 1637\n",
      "Working on 1638\n",
      "Working on 1639\n",
      "Working on 1640\n",
      "Working on 1641\n",
      "Working on 1642\n",
      "Working on 1643\n",
      "Working on 1644\n",
      "Working on 1645\n",
      "Working on 1646\n",
      "Working on 1647\n",
      "Working on 1648\n",
      "Working on 1649\n",
      "Working on 1650\n",
      "Working on 1651\n",
      "Working on 1652\n",
      "Working on 1653\n",
      "Working on 1654\n",
      "Working on 1655\n",
      "Working on 1656\n",
      "Working on 1657\n",
      "Working on 1658\n",
      "Working on 1659\n",
      "Working on 1660\n",
      "Working on 1661\n",
      "Working on 1662\n",
      "Working on 1663\n",
      "Working on 1664\n",
      "Working on 1665\n",
      "Working on 1666\n",
      "Working on 1667\n",
      "Working on 1668\n",
      "Working on 1669\n",
      "Working on 1670\n",
      "Working on 1671\n",
      "Working on 1672\n",
      "Working on 1673\n",
      "Working on 1674\n",
      "Working on 1675\n",
      "Working on 1676\n",
      "Working on 1677\n",
      "Working on 1678\n",
      "Working on 1679\n",
      "Working on 1680\n",
      "Working on 1681\n",
      "Working on 1682\n",
      "Working on 1683\n",
      "Working on 1684\n",
      "Working on 1685\n",
      "Working on 1686\n",
      "Working on 1687\n",
      "Working on 1688\n",
      "Working on 1689\n",
      "Working on 1690\n",
      "Working on 1691\n",
      "Working on 1692\n",
      "Working on 1693\n",
      "Working on 1694\n",
      "Working on 1695\n",
      "Working on 1696\n",
      "Working on 1697\n",
      "Working on 1698\n",
      "Working on 1699\n",
      "Working on 1700\n",
      "Working on 1701\n",
      "Working on 1702\n",
      "Working on 1703\n",
      "Working on 1704\n",
      "Working on 1705\n",
      "Working on 1706\n",
      "Working on 1707\n",
      "Working on 1708\n",
      "Working on 1709\n",
      "Working on 1710\n",
      "Working on 1711\n",
      "Working on 1712\n",
      "Working on 1713\n",
      "Working on 1714\n",
      "Working on 1715\n",
      "Working on 1716\n",
      "Working on 1717\n",
      "Working on 1718\n",
      "Working on 1719\n",
      "Working on 1720\n",
      "Working on 1721\n",
      "Working on 1722\n",
      "Working on 1723\n",
      "Working on 1724\n",
      "Working on 1725\n",
      "Working on 1726\n",
      "Working on 1727\n",
      "Working on 1728\n",
      "Working on 1729\n",
      "Working on 1730\n",
      "Working on 1731\n",
      "Working on 1732\n",
      "Working on 1733\n",
      "Working on 1734\n",
      "Working on 1735\n",
      "Working on 1736\n",
      "Working on 1737\n",
      "Working on 1738\n",
      "Working on 1739\n",
      "Working on 1740\n",
      "Working on 1741\n",
      "Working on 1742\n",
      "Working on 1743\n",
      "Working on 1744\n",
      "Working on 1745\n",
      "Working on 1746\n",
      "Working on 1747\n",
      "Working on 1748\n"
     ]
    }
   ],
   "source": [
    "## Temporal Features\n",
    "# create columns\n",
    "df['IsOpen_yesterday'] = np.empty(len(df))\n",
    "df['IsOpen_tomorrow'] = np.empty(len(df))\n",
    "df['IsHoliday_yesterday'] = np.empty(len(df))\n",
    "df['IsHoliday_tomorrow'] = np.empty(len(df))\n",
    "df['NumberOfSales_yesterday'] = np.empty(len(df))\n",
    "df['NumberOfSales_lastweek'] = np.empty(len(df))\n",
    "df['NumberOfSales_lastmonth'] = np.empty(len(df))\n",
    "\n",
    "for store in df.StoreID.unique():\n",
    "    print(\"Working on {}\".format(store))\n",
    "    temp = df.loc[df.StoreID == store]\n",
    "    # switch index to timestamps to make this easier\n",
    "    oldindex = temp.index\n",
    "    temp.index = temp['Date']\n",
    "    \n",
    "    temp['IsOpen_yesterday'] = temp.IsOpen.rolling(window='1d',closed='left', min_periods=1).sum()\n",
    "    temp['IsOpen_tomorrow'] = temp.IsOpen.rolling(window='1d',closed='left', min_periods=1).sum().shift(-2, '1d')\n",
    "    temp['IsHoliday_yesterday'] = temp.IsHoliday.rolling(window='1d',closed='left', min_periods=1).sum()\n",
    "    temp['IsHoliday_tomorrow'] = temp.IsHoliday.rolling(window='1d',closed='left', min_periods=1).sum().shift(-2, '1d')\n",
    "    temp['NumberOfSales_yesterday'] = temp.NumberOfSales.rolling(window='1d',closed='left', min_periods=1).sum()\n",
    "    temp['NumberOfSales_lastweek'] = temp.NumberOfSales.rolling(window='7d',closed='left', min_periods=1).sum()\n",
    "    temp['NumberOfSales_lastmonth'] = temp.NumberOfSales.rolling(window='30d',closed='left', min_periods=1).sum()\n",
    "    \n",
    "    # put it back in the dataframe\n",
    "    temp.index = oldindex\n",
    "    df.loc[df.StoreID == store] = temp\n",
    "    \n",
    "# Attenzione: i valori di tomorrow nel test sono sputtanati a NaN\n",
    "# vanno messi a mano qui o cambiato il modo di calcolo\n",
    "    \n",
    "# drop rows at the beginning where we have no past information\n",
    "# NB: possiamo fare a meno se togliamo quelle feature\n",
    "df = df.iloc[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['StoreType'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-2f997e1cf7ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m  \u001b[1;31m## StoreType\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'StoreType'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'StoreType'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m  \u001b[1;31m## AssortmentType\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first)\u001b[0m\n\u001b[0;32m   1202\u001b[0m             \u001b[0mwith_dummies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1204\u001b[1;33m             \u001b[0mwith_dummies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns_to_encode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns_to_encode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix_sep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   2528\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2529\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2530\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2532\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   2560\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2561\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2562\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2563\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2564\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   3742\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3743\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[1;32m-> 3744\u001b[1;33m                                  labels[mask])\n\u001b[0m\u001b[0;32m   3745\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3746\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: labels ['StoreType'] not contained in axis"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding\n",
    "# nb: pd.get_dummies rimuove le colonne direttamente\n",
    "\n",
    "# ## StoreId\n",
    "# df = pd.get_dummies(df, columns=['StoreID'], prefix='StoreID')\n",
    "\n",
    " ## StoreType\n",
    "# df = pd.get_dummies(df, columns=['StoreType'], prefix='StoreType')\n",
    "\n",
    " ## AssortmentType\n",
    "# df = pd.get_dummies(df, columns=['AssortmentType'], prefix='AssortmentType')\n",
    "\n",
    "# ## Region\n",
    "# df = pd.get_dummies(df, columns=['Region'], prefix='Region')\n",
    "\n",
    "# ## Events\n",
    "# df = pd.get_dummies(df, columns=['Events'], prefix='Events', dummy_na=True)\n",
    "### inutile se possiamo usare categorie con decision tree\n",
    "\n",
    "# numeric features to categories (strings)\n",
    "# df.StoreID = df.StoreID.astype(str)\n",
    "# df.Region = df.Region.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns\n",
    "df = df.drop('Date', axis=1)\n",
    "df = df.drop('NumberOfCustomers', axis=1)  \n",
    "df = df.drop('WindDirDegrees', axis=1)\n",
    "\n",
    "# questi non cambiano mai, teniamo regione e population\n",
    "df = df.drop('Region_AreaKM2', axis=1)\n",
    "df = df.drop('Region_GDP', axis=1)\n",
    "#df = df.drop('Region_PopulationK', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AssortmentType</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>Events</th>\n",
       "      <th>HasPromotions</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>IsOpen</th>\n",
       "      <th>Max_Dew_PointC</th>\n",
       "      <th>Max_Gust_SpeedKm_h</th>\n",
       "      <th>Max_Humidity</th>\n",
       "      <th>Max_Sea_Level_PressurehPa</th>\n",
       "      <th>...</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>IsOpen_yesterday</th>\n",
       "      <th>IsOpen_tomorrow</th>\n",
       "      <th>IsHoliday_yesterday</th>\n",
       "      <th>IsHoliday_tomorrow</th>\n",
       "      <th>NumberOfSales_yesterday</th>\n",
       "      <th>NumberOfSales_lastweek</th>\n",
       "      <th>NumberOfSales_lastmonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>General</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Fog-Rain-Snow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1009</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11907.0</td>\n",
       "      <td>51996.0</td>\n",
       "      <td>194456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>General</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>87</td>\n",
       "      <td>1009</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44106.0</td>\n",
       "      <td>186345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>General</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Snow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>81</td>\n",
       "      <td>1013</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11129.0</td>\n",
       "      <td>49230.0</td>\n",
       "      <td>197474.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>General</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>86</td>\n",
       "      <td>1013</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49230.0</td>\n",
       "      <td>189174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>General</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>65</td>\n",
       "      <td>1013</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40680.0</td>\n",
       "      <td>182020.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AssortmentType  CloudCover         Events  HasPromotions  IsHoliday  \\\n",
       "30        General         6.0  Fog-Rain-Snow              1          1   \n",
       "31        General         6.0            NaN              0          0   \n",
       "32        General         5.0           Snow              0          0   \n",
       "33        General         2.0            NaN              0          1   \n",
       "34        General         1.0            NaN              0          0   \n",
       "\n",
       "    IsOpen  Max_Dew_PointC  Max_Gust_SpeedKm_h  Max_Humidity  \\\n",
       "30       0               0                14.0           100   \n",
       "31       1              -2                21.0            87   \n",
       "32       0              -2                24.0            81   \n",
       "33       0              -4                24.0            86   \n",
       "34       1              -5                45.0            65   \n",
       "\n",
       "    Max_Sea_Level_PressurehPa           ...             Month  Week  Quarter  \\\n",
       "30                       1009           ...                 4    13        2   \n",
       "31                       1009           ...                 4    13        2   \n",
       "32                       1013           ...                 4    13        2   \n",
       "33                       1013           ...                 4    14        2   \n",
       "34                       1013           ...                 4    14        2   \n",
       "\n",
       "    IsOpen_yesterday  IsOpen_tomorrow  IsHoliday_yesterday  \\\n",
       "30               1.0              1.0                  0.0   \n",
       "31               0.0              0.0                  1.0   \n",
       "32               1.0              0.0                  0.0   \n",
       "33               0.0              1.0                  0.0   \n",
       "34               0.0              1.0                  1.0   \n",
       "\n",
       "    IsHoliday_tomorrow  NumberOfSales_yesterday  NumberOfSales_lastweek  \\\n",
       "30                 0.0                  11907.0                 51996.0   \n",
       "31                 0.0                      0.0                 44106.0   \n",
       "32                 1.0                  11129.0                 49230.0   \n",
       "33                 0.0                      0.0                 49230.0   \n",
       "34                 0.0                      0.0                 40680.0   \n",
       "\n",
       "    NumberOfSales_lastmonth  \n",
       "30                 194456.0  \n",
       "31                 186345.0  \n",
       "32                 197474.0  \n",
       "33                 189174.0  \n",
       "34                 182020.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AssortmentType', 'CloudCover', 'Events', 'HasPromotions', 'IsHoliday', 'IsOpen', 'Max_Dew_PointC', 'Max_Gust_SpeedKm_h', 'Max_Humidity', 'Max_Sea_Level_PressurehPa', 'Max_TemperatureC', 'Max_VisibilityKm', 'Max_Wind_SpeedKm_h', 'Mean_Dew_PointC', 'Mean_Humidity', 'Mean_Sea_Level_PressurehPa', 'Mean_TemperatureC', 'Mean_VisibilityKm', 'Mean_Wind_SpeedKm_h', 'Min_Dew_PointC', 'Min_Humidity', 'Min_Sea_Level_PressurehPa', 'Min_TemperatureC', 'Min_VisibilitykM', 'NearestCompetitor', 'NumberOfSales', 'Precipitationmm', 'Region', 'Region_PopulationK', 'StoreID', 'StoreType', 'DayOfWeek', 'Month', 'Week', 'Quarter', 'IsOpen_yesterday', 'IsOpen_tomorrow', 'IsHoliday_yesterday', 'IsHoliday_tomorrow', 'NumberOfSales_yesterday', 'NumberOfSales_lastweek', 'NumberOfSales_lastmonth']\n"
     ]
    }
   ],
   "source": [
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save preprocessed data\n",
    "df[:-len_test].to_csv('preprocessed_train.csv',index=False)\n",
    "df[-len_test:].to_csv('preprocessed_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REMEMBER\n",
    "# le sales di testing vanno aggiunte e sistemate a runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('preprocessed_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistemo i dati per regression tree\n",
    "\n",
    "# One-Hot Encoding \n",
    "# nb: pd.get_dummies rimuove le colonne direttamente\n",
    "\n",
    "# ## StoreId\n",
    "# df = pd.get_dummies(df, columns=['StoreID'], prefix='StoreID')\n",
    "\n",
    "df.drop('StoreID',axis=1)\n",
    "\n",
    " ## StoreType\n",
    "df = pd.get_dummies(df, columns=['StoreType'], prefix='StoreType')\n",
    "\n",
    " ## AssortmentType\n",
    "df = pd.get_dummies(df, columns=['AssortmentType'], prefix='AssortmentType')\n",
    "\n",
    "# ## Region\n",
    "df = pd.get_dummies(df, columns=['Region'], prefix='Region')\n",
    "\n",
    "# ## Events\n",
    "# df = pd.get_dummies(df, columns=['Events'], prefix='Events', dummy_na=True)\n",
    "### inutile se possiamo usare categorie con decision tree\n",
    "\n",
    "# numeric features to categories (strings)\n",
    "#df.StoreID = df.StoreID.astype(str)\n",
    "#df.Region = df.Region.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CloudCover                                             6\n",
       "Events                                     Fog-Rain-Snow\n",
       "HasPromotions                                          1\n",
       "IsHoliday                                              1\n",
       "IsOpen                                                 0\n",
       "Max_Dew_PointC                                         0\n",
       "Max_Gust_SpeedKm_h                                    14\n",
       "Max_Humidity                                         100\n",
       "Max_Sea_Level_PressurehPa                           1009\n",
       "Max_TemperatureC                                       4\n",
       "Max_VisibilityKm                                      11\n",
       "Max_Wind_SpeedKm_h                                    14\n",
       "Mean_Dew_PointC                                       -2\n",
       "Mean_Humidity                                         78\n",
       "Mean_Sea_Level_PressurehPa                          1008\n",
       "Mean_TemperatureC                                      1\n",
       "Mean_VisibilityKm                                      7\n",
       "Mean_Wind_SpeedKm_h                                    6\n",
       "Min_Dew_PointC                                        -3\n",
       "Min_Humidity                                          52\n",
       "Min_Sea_Level_PressurehPa                           1006\n",
       "Min_TemperatureC                                      -2\n",
       "Min_VisibilitykM                                       2\n",
       "NearestCompetitor                                    326\n",
       "NumberOfSales                                          0\n",
       "Precipitationmm                                        0\n",
       "Region_PopulationK                                  2770\n",
       "StoreID                                             1000\n",
       "DayOfWeek                                              4\n",
       "Month                                                  4\n",
       "Week                                                  13\n",
       "Quarter                                                2\n",
       "IsOpen_yesterday                                       1\n",
       "IsOpen_tomorrow                                        1\n",
       "IsHoliday_yesterday                                    0\n",
       "IsHoliday_tomorrow                                     0\n",
       "NumberOfSales_yesterday                            11907\n",
       "NumberOfSales_lastweek                             51996\n",
       "NumberOfSales_lastmonth                           194456\n",
       "StoreType_Hyper Market                                 1\n",
       "StoreType_Shopping Center                              0\n",
       "StoreType_Standard Market                              0\n",
       "StoreType_Super Market                                 0\n",
       "AssortmentType_General                                 1\n",
       "AssortmentType_With Fish Department                    0\n",
       "AssortmentType_With Non-Food Department                0\n",
       "Region_0                                               0\n",
       "Region_1                                               0\n",
       "Region_2                                               0\n",
       "Region_3                                               0\n",
       "Region_4                                               0\n",
       "Region_5                                               0\n",
       "Region_6                                               0\n",
       "Region_7                                               1\n",
       "Region_8                                               0\n",
       "Region_9                                               0\n",
       "Region_10                                              0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Events'] = df['Events'].fillna('Sun')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 2, 1, 4], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.replace({'Sun':0,'Rain' :1 ,'Thunderstorm':1,'Fog':1,'Snow' : 2 ,'Fog-Rain' : 2 ,'Rain-Thunderstorm' : 2 ,'Rain-Snow' : 2 ,'Fog-Snow' : 2 ,'Fog-Rain-Snow' : 3 ,'Rain-Hail': 3,'Snow-Hail': 3,'Rain-Snow-Hail': 3,'Fog-Rain-Hail': 3,'Fog-Thunderstorm': 3,'Fog-Rain-Thunderstorm':4,'Fog-Snow-Hail':4,'Fog-Rain-Snow-Hail':4, 'Rain-Snow-Thunderstorm':4,'Rain-Hail-Thunderstorm':4, 'Fog-Rain-Hail-Thunderstorm':4,'Rain-Snow-Hail-Thunderstorm':4})\n",
    "\n",
    "df['Events'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CloudCover                                      6.0\n",
       "Events                                          3.0\n",
       "HasPromotions                                   1.0\n",
       "IsHoliday                                       1.0\n",
       "IsOpen                                          0.0\n",
       "Max_Dew_PointC                                  0.0\n",
       "Max_Gust_SpeedKm_h                             14.0\n",
       "Max_Humidity                                  100.0\n",
       "Max_Sea_Level_PressurehPa                    1009.0\n",
       "Max_TemperatureC                                4.0\n",
       "Max_VisibilityKm                               11.0\n",
       "Max_Wind_SpeedKm_h                             14.0\n",
       "Mean_Dew_PointC                                -2.0\n",
       "Mean_Humidity                                  78.0\n",
       "Mean_Sea_Level_PressurehPa                   1008.0\n",
       "Mean_TemperatureC                               1.0\n",
       "Mean_VisibilityKm                               7.0\n",
       "Mean_Wind_SpeedKm_h                             6.0\n",
       "Min_Dew_PointC                                 -3.0\n",
       "Min_Humidity                                   52.0\n",
       "Min_Sea_Level_PressurehPa                    1006.0\n",
       "Min_TemperatureC                               -2.0\n",
       "Min_VisibilitykM                                2.0\n",
       "NearestCompetitor                             326.0\n",
       "NumberOfSales                                   0.0\n",
       "Precipitationmm                                 0.0\n",
       "Region_PopulationK                           2770.0\n",
       "StoreID                                      1000.0\n",
       "DayOfWeek                                       4.0\n",
       "Month                                           4.0\n",
       "Week                                           13.0\n",
       "Quarter                                         2.0\n",
       "IsOpen_yesterday                                1.0\n",
       "IsOpen_tomorrow                                 1.0\n",
       "IsHoliday_yesterday                             0.0\n",
       "IsHoliday_tomorrow                              0.0\n",
       "NumberOfSales_yesterday                     11907.0\n",
       "NumberOfSales_lastweek                      51996.0\n",
       "NumberOfSales_lastmonth                    194456.0\n",
       "StoreType_Hyper Market                          1.0\n",
       "StoreType_Shopping Center                       0.0\n",
       "StoreType_Standard Market                       0.0\n",
       "StoreType_Super Market                          0.0\n",
       "AssortmentType_General                          1.0\n",
       "AssortmentType_With Fish Department             0.0\n",
       "AssortmentType_With Non-Food Department         0.0\n",
       "Region_0                                        0.0\n",
       "Region_1                                        0.0\n",
       "Region_2                                        0.0\n",
       "Region_3                                        0.0\n",
       "Region_4                                        0.0\n",
       "Region_5                                        0.0\n",
       "Region_6                                        0.0\n",
       "Region_7                                        1.0\n",
       "Region_8                                        0.0\n",
       "Region_9                                        0.0\n",
       "Region_10                                       0.0\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split trainset in data and target\n",
    "y = df[\"NumberOfSales\"]\n",
    "X = df.drop('NumberOfSales', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as mp\n",
    "np.any(np.isfinite(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-d83a977a5465>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mforest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExtraTreesRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \"\"\"\n\u001b[0;32m    246\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 44\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "forest = ExtraTreesRegressor(n_estimators=250, random_state=0)\n",
    "forest.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], data.feature_names[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), data.feature_names[indices],rotation=90)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_model = SelectFromModel(forest, prefit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected_features_forest = feature_selection_model.transform(X)\n",
    "X_selected_features_forest.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
